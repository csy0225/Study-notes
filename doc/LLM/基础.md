# 一、基础
## 1.1 TopK 和 TopP
### 1.1.1 概念
+ topK 是获取预测结果中概率最高的前 K 个。
+ topP 是获取累积概率达到 P% 的所有结果。
举个例子：
    - top5: k = 5, 表示获取前 5 个结果。
    - top0.3: 表示获取累积概率达到 30% 的所有结果。
### 1.1.2 例子
```
{
    "I": 0.2,
    "love": 0.3,
    "to": 0.15,
    "eat": 0.15,
    "apples": 0.1,
    "bananas": 0.05,
    "oranges": 0.05,
}
```
如果我们设置top_p = 0.7，那么我们要取到最少的概率，使得它们加起来大于 0.7，在这个例子中，我们首先按照概率从高到低进行排序，得到：
```
[{"love": 0.3,  "I": 0.2, "to": 0.15, "eat": 0.15, "apples": 0.1, "bananas": 0.05, "oranges": 0.05,}]
```
然后我们从高到低将概率加起来，直到累计概率大于等于 0.7 为止。在这个例子中，我们需要取到前三个词，因为他们的概率加起来为 0.65，而第四个概率为 0.15，加上前三个词就超过了 0.7。因此，经过 topp 筛选后，我们的候选词为 "I", "love", "to" （具体边界值怎么取应该是取决于算法，看底层怎么实现的了）需要注意的是，如果排完序后第一个词的概率已经大于等于 "top_p", 那么只会选择这个词，不会选择后面的词。

### 1.1.3 特点
|特点|top-p|top-k|
|---|---|---|
|定义|在概率累积到超过阈值时停止采样，保证采样出的概率总和不超过阈值|选择概率最高的 K 个单词，忽略其余单词|
|取样个数|取样数量不确定|取样数量确定|
|采样质量|采样质量随阈值变化而变化，更灵活|采样质量固定，更稳定|
|适用场景|适用于生成多样性的文本，可控制多样性程度|适用于生成最佳结果，适合生成任务|

### 1.1.4 temperature
temperature 是神经网络中用于控制模型输出的一个超参数。它与 topK 和 topP 一起使用，可以影响模型的输出结果。
temperature 的作用是 **【软化】** 模型的输出概率分布。当 temperature 增加时，概率分布会更加均匀柔和；当 temperature 减小时，概率分布会更加集中于最大值。所以，改变 temperature 可以在一定程度上控制模型输出的 **【确定性】**。 **高 temperature 会产生更加多样的输出，产生更多候选结果。低 temperature 会产生更少但是更加确认信赖的输出，与 topK 和 topP 一起使用时，temperature 可以影响最终的采样结果。** 
+ 当时用 topK 时：
  + 高 temperature 会使更多结果的概率接近最大值，所以 topK 的结果会更加多样。
  + 低 temperature 会使概率更加集中于真正的 K 个最大值，所以 topK 的结果会更加稳定。
+ 当使用 topP 时：
  + 高 temperature 会使更多结果的概率总和达到 P, 所以会采样出更多结果。
  + 低 temperature 下，只有真正概率较高的结果才会使累积概率达到 P, 所以结果数量会较少。

执行流程： 模型原始输出（概率） -> 使用 temperature 软化概率 -> topK/topP 采样 -> 输出结果。

+ 示例：假设一个分类模型对 3 个类别的预测概率分别为：A: 0.6, B: 0.3, C: 0.1
  + 1、 如果使用 temperature = 0.5，那么 softmax 后的概率分布会是 A: 0.46, B: 0.31, C: 0.23
  + 2、 如果使用 top2（K = 2）, 那么结果会是 [A, B]
  + 3、 如果使用 top0.6，那么结果也会是 [A,B]，如果不用 temperature，那么结果只会是 [A].

### 1.1.5 三者作用
在同样的数据集、同样的词表下，temperature、topp 和 topk 三者都能影响文本的长度。其中，temperature 主要影响文本的多样性和随机性，通过改变概率分布的 "平缓程度" 来控制生成的文本多样性; topP 主要影响文本的生成长度，控制生成的文本在保证一定的多样性的前提下，生成的长度上限；而 topk 主要影响文本生成长度下限，控制生成的文本在保证一定的多样性前提下，生成的长度下限。

### 1.1.6 为什么需要同时设置 topk 和 topp
+ topk 用于限制生成文本的词汇表范围，只有前 K 个最可能的词才会被考虑，因此生成的文本通常比较短。
+ topp 用于控制生成文本的多样性，限制生成文本的词汇表范围，使得概率之和大于一定的阈值 p，因此生成的文本通常比较长，也更加多样化。

因此，当只设置 topk 时，生成的文本会比较简短，而且会比较单一；而当只设置 topp 时，生成的文本会比较长，但可能会缺乏一定的准确性。为了既保证文本的多样性，又不失准确性，同时使用 topp 和 topk 是一个不错的选择。

## 1.2 Token
Token 是文本中的最小单位。 对于模型而言，token 是一种数字化的表示形式，每个 token 都与一个唯一的数字 ID 相关联，模型通过这些 ID 来区分不同的 token。
### 1.2.1 为什么 token 有长度限制
+ 计算资源：处理长序列需要更多的计算资源和内存。随着输入长度的增加，模型的计算量也随之增加。为了保证模型能够在合理的时间内完成计算，所以需要对输入长度进行限制。
+ 内存限制

参考链接：https://zhuanlan.zhihu.com/p/630123214?utm_id=0

## 1.3 词嵌入（word embedding）
embedding 就是用一个低维稠密的向量 "表示" 一个对象。
### 1.3.1 embedding 是怎么得到的？
embedding 是神经网络训练出来的，比如 Word2Vec、GloVe 以及 Transformer，这些都是一些语言模型。在预训练阶段，embedding 都是随机初始化的，经过预训练之后，就可以得到词向量。
